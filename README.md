# Agente Conversacional com Google ADK + LiteLLM

Este projeto Ã© um agente conversacional baseado no [Google ADK](https://github.com/google/adk-python) com suporte a LLMs via [LiteLLM](https://github.com/BerriAI/litellm). Ele Ã© configurado para consumir ferramentas (tools) do tipo **MCP** (Model Context Protocol), exclusivamente via **HTTP/SSE**, rodando cada tool em seu prÃ³prio contÃªiner.

## ğŸ¯ VisÃ£o Geral

O agente se comunica com servidores MCP expostos em diferentes portas. Cada ferramenta MCP Ã© servida por um contÃªiner prÃ³prio (ex: `mcp-filesystem`, `mcp-greeter`). Todas as ferramentas sÃ£o acessadas via `MCPToolRegistry` por meio de endpoints definidos em `config_sse_tools.yaml`.

## ğŸ“ Estrutura do Projeto

```
my-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ data/                       # Ponto de montagem para volumes e compartilhamentos entre containers
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ tool_registry.py
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ mcp-greeter/            # Exemplo de ferramenta personalizada criada com FastAPI e FastApiMCP
â”‚       â”œâ”€â”€ .env
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ Dockerfile          # Container da ferramenta personalizada
â”œâ”€â”€ config_sse_tools.yaml       # Endpoints MCP via HTTP/SSE
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile                  # Container do agente
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos containers
â””â”€â”€ README.md
```

## â–¶ï¸ Como Rodar

### 1. Build

```bash
docker compose build
```

### 2. Interagir com o agente

```bash
docker compose run --rm agente
```

O agente roda em terminal interativo. VocÃª verÃ¡ o prompt:

![Running example](running-example.png)

Digite sua pergunta ou comando, e o agente responde ou chama uma tool registrada.

---

## ğŸ”§ ConfiguraÃ§Ã£o

### `.env`

```env
LITELLM_API_KEY=sk-...
LITELLM_MODEL=openai/gpt-4
AGENT_NAME=assistente_mcp
AGENT_INSTRUCTION=VocÃª Ã© um assistente tÃ©cnico direto e confiÃ¡vel.
AGENT_USER_ID=usuario123
```

---

## ğŸ›°ï¸ MCP Servers no `docker-compose.yml`

### Agente + 2 MCP servers (filesystem + greeter)

```yaml
services:

  agente:
    build: .
    env_file: .env
    volumes:
      - ./tools:/app/tools
    depends_on:
      - mcp-filesystem
      - mcp-greeter
    stdin_open: true
    tty: true

  mcp-filesystem:
    image: node:18
    working_dir: /mcp
    container_name: mcp-filesystem
    volumes:
      - ./data:/mcp
    ports:
      - "3000:3000"
    command: >
      npx -y supergateway \
        --stdio "npx -y @modelcontextprotocol/server-filesystem ." \
        --port 3000 \
        --baseUrl http://0.0.0.0:3000 \
        --ssePath /sse \
        --messagePath /messages

  mcp-greeter:
    build:
      context: ./tools/mcp-greeter
    env_file: ./tools/mcp-greeter/.env
    ports:
      - "3001:3000"
```

---

## ğŸ”§ Exemplo de Tool: `mcp-greeter`

### Estrutura Final

```
tools/mcp-greeter/
â”œâ”€â”€ .env
â”œâ”€â”€ main.py
â””â”€â”€ Dockerfile
```

### `.env`
```
GREETER_PORT=3000
```

### `main.py`

```python
import os
from fastapi import FastAPI
from fastapi_mcp import FastApiMCP
from pydantic import BaseModel

PORT = int(os.getenv("GREETER_PORT"))

class GreetRequest(BaseModel):
    name: str

app = FastAPI()

mcp = FastApiMCP(
    app,
    name="Greeter API",
    description="A simple example API using FastAPI and FastApiMCP",
    base_url=f"http://localhost:{PORT}",
    describe_all_responses=True,
    describe_full_response_schema=True
)

@app.post("/greet",  operation_id="greet_user")
async def greet(data: GreetRequest):
    return {"output": f"Hello, {data.name}! **Greetings** from Greeter API!"}

mcp.mount()
mcp.setup_server()
```

### `Dockerfile`

```Dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY . .

RUN pip install --no-cache-dir fastapi uvicorn fastapi-mcp

CMD ["sh", "-c", "uvicorn main:app --host 0.0.0.0 --port ${GREETER_PORT}"]
```

> **Nota:** Esta versÃ£o do `greeter` utiliza `fastapi_mcp`, que adiciona suporte nativo a MCP em aplicaÃ§Ãµes FastAPI.

---

## âš™ï¸ Exemplo: Tool stdio exposta com Supergateway

Uma ferramenta que roda via `stdio` pode ser convertida para o formato HTTP/SSE usando [supergateway](https://github.com/supercorp-ai/supergateway).

### `docker-compose.yml`

```yaml
mcp-filesystem:
  image: node:18
  working_dir: /mcp
  container_name: mcp-filesystem
  volumes:
    - ./data:/mcp
  ports:
    - "3000:3000"
  command: >
    npx -y supergateway \
      --stdio "npx -y @modelcontextprotocol/server-filesystem ." \
      --port 3000 \
      --baseUrl http://0.0.0.0:3000 \
      --ssePath /sse \
      --messagePath /messages
```

### `config_sse_tools.yaml`

```yaml
tools:
  - id: filesystem
    url: http://mcp-filesystem:3000/sse
  - id: greeter
    url: http://mcp-greeter:3001/sse
```

Essa configuraÃ§Ã£o transforma a ferramenta `@modelcontextprotocol/server-filesystem` â€” que originalmente usa `stdio` â€” em um servidor HTTP/SSE compatÃ­vel com ADK via `supergateway`.

---

## ğŸ’¬ ObservaÃ§Ãµes Finais

- Ferramentas MCP sÃ£o registradas usando `MCPToolset` com `SseServerParams`.
- Atualmente, este agente consome apenas ferramentas MCP expostas via HTTP/SSE.
- O agente Ã© construÃ­do via funÃ§Ã£o assÃ­ncrona `build_agent()` para carregamento dinÃ¢mico.
- Ferramentas podem rodar em contÃªiner prÃ³prio.
- VocÃª tambÃ©m pode encapsular tools stdio com [supergateway](https://github.com/supercorp-ai/supergateway) para expor via HTTP/SSE.

---

## ğŸ§¼ LicenÃ§a
Uso pessoal e experimental. Use com sabedoria e, de preferÃªncia, longe de um cluster de produÃ§Ã£o.